/**
 * í†µí•© ê²€ìƒ‰ ì—”ì§„
 * ì¤‘ë³µì„ ì œê±°í•˜ê³  ì„±ëŠ¥ì„ ìµœì í™”í•œ ë‹¨ì¼ ê²€ìƒ‰ ì‹œìŠ¤í…œ
 */

import { Chunk, QuestionAnalysis } from '../types';
import { FirestoreService, PDFChunk } from './firestoreService';
import { ContextQualityOptimizer, EnhancedChunk } from './contextQualityOptimizer';
import { UnifiedSynonymService } from './unifiedSynonymService';
import { ComprehensiveSynonymExpansion } from './comprehensiveSynonymExpansion';
import { LocalEmbeddingService } from './localEmbeddingService';

export interface UnifiedSearchResult {
  chunks: EnhancedChunk[];
  searchMetrics: {
    totalProcessed: number;
    uniqueResults: number;
    averageRelevance: number;
    executionTime: number;
    scoreBreakdown: {
      keyword: number;
      synonym: number;
      semantic: number;
    };
  };
}

export interface ScoredChunk {
  chunk: PDFChunk | Chunk;
  score: number;
  breakdown: {
    keyword: number;
    synonym: number;
    semantic: number;
  };
}

export class UnifiedSearchEngine {
  private firestoreService: FirestoreService;
  private unifiedSynonymService: UnifiedSynonymService;
  private comprehensiveSynonymExpansion: ComprehensiveSynonymExpansion;
  private localEmbeddingService: LocalEmbeddingService;
  
  constructor() {
    this.firestoreService = FirestoreService.getInstance();
    this.unifiedSynonymService = UnifiedSynonymService.getInstance();
    this.comprehensiveSynonymExpansion = ComprehensiveSynonymExpansion.getInstance();
    this.localEmbeddingService = new LocalEmbeddingService();
  }

  /**
   * í†µí•© ê²€ìƒ‰ ì‹¤í–‰ (ì¤‘ë³µ ì œê±° + ì„±ëŠ¥ ìµœì í™”)
   */
  async executeUnifiedSearch(
    questionAnalysis: QuestionAnalysis,
    maxChunks: number = 20
  ): Promise<UnifiedSearchResult> {
    const startTime = Date.now();
    console.log(`ğŸš€ í†µí•© ê²€ìƒ‰ ì‹œì‘: "${questionAnalysis.context}"`);
    
    try {
      // 1ë‹¨ê³„: ë‹¨ì¼ Firestore ì¿¼ë¦¬ë¡œ ëŒ€ëŸ‰ ë°ì´í„° ë¡œë“œ
      console.log('ğŸ” Firestore ëŒ€ëŸ‰ ë°ì´í„° ë¡œë“œ...');
      const allChunks = await this.fetchChunksInBulk(
        questionAnalysis.keywords,
        questionAnalysis.expandedKeywords || [],
        500
      );
      
      console.log(`âœ… ëŒ€ëŸ‰ ë°ì´í„° ë¡œë“œ ì™„ë£Œ: ${allChunks.length}ê°œ ì²­í¬`);
      
      // 2ë‹¨ê³„: ë‹¤ì–‘í•œ ìŠ¤ì½”ì–´ë§ ë°©ì‹ ì ìš©
      console.log('ğŸ“Š ë‹¤ì¤‘ ì „ëµ ìŠ¤ì½”ì–´ë§ ì‹œì‘...');
      const scoredChunks = await this.scoreChunksByMultipleStrategies(
        allChunks,
        questionAnalysis
      );
      
      console.log(`âœ… ìŠ¤ì½”ì–´ë§ ì™„ë£Œ: ${scoredChunks.length}ê°œ ì²­í¬`);
      
      // 3ë‹¨ê³„: ê²°ê³¼ ì •ë ¬ ë° ì¤‘ë³µ ì œê±°
      const uniqueChunks = this.removeDuplicatesAndRank(
        scoredChunks,
        maxChunks
      );
      
      console.log(`âœ… ì¤‘ë³µ ì œê±° ì™„ë£Œ: ${uniqueChunks.length}ê°œ ìµœì¢… ê²°ê³¼`);
      
      // 4ë‹¨ê³„: ì»¨í…ìŠ¤íŠ¸ í’ˆì§ˆ ìµœì í™”
      const chunks = uniqueChunks.map(scored => {
        const chunk: EnhancedChunk = {
          ...(scored.chunk as Chunk),
          relevanceScore: scored.score,
          qualityScore: scored.score
        };
        return chunk;
      });
      
      const optimizedChunks = ContextQualityOptimizer.optimizeContextQuality(
        chunks,
        questionAnalysis,
        maxChunks
      );
      
      const executionTime = Date.now() - startTime;
      
      // ì ìˆ˜ í†µê³„ ê³„ì‚°
      const scoreBreakdown = this.calculateScoreBreakdown(scoredChunks);
      
      const result: UnifiedSearchResult = {
        chunks: optimizedChunks,
        searchMetrics: {
          totalProcessed: allChunks.length,
          uniqueResults: optimizedChunks.length,
          averageRelevance: this.calculateAverageRelevance(optimizedChunks),
          executionTime,
          scoreBreakdown
        }
      };
      
      console.log(`ğŸ‰ í†µí•© ê²€ìƒ‰ ì™„ë£Œ: ${optimizedChunks.length}ê°œ ìµœì¢… ê²°ê³¼, ${executionTime}ms`);
      console.log(`ğŸ“Š í‰ê·  ê´€ë ¨ì„±: ${result.searchMetrics.averageRelevance.toFixed(3)}`);
      console.log(`ğŸ“Š ì ìˆ˜ ë¶„í¬: í‚¤ì›Œë“œ ${scoreBreakdown.keyword.toFixed(2)}, ë™ì˜ì–´ ${scoreBreakdown.synonym.toFixed(2)}, ì˜ë¯¸ ${scoreBreakdown.semantic.toFixed(2)}`);
      
      return result;
      
    } catch (error) {
      console.error('âŒ í†µí•© ê²€ìƒ‰ ì˜¤ë¥˜:', error);
      throw error;
    }
  }
  
  /**
   * ë‹¨ì¼ Firestore ì¿¼ë¦¬ë¡œ ëŒ€ëŸ‰ ë°ì´í„° ë¡œë“œ
   */
  private async fetchChunksInBulk(
    keywords: string[],
    expandedKeywords: string[],
    limit: number = 500
  ): Promise<PDFChunk[]> {
    try {
      // í‚¤ì›Œë“œ í†µí•© (ì¤‘ë³µ ì œê±°)
      const allKeywords = [...new Set([...keywords, ...expandedKeywords])];
      
      console.log(`ğŸ” í†µí•© í‚¤ì›Œë“œ: ${allKeywords.length}ê°œ (ì›ë³¸: ${keywords.length}, í™•ì¥: ${expandedKeywords.length})`);
      
      // Firestoreì—ì„œ ëª¨ë“  ì²­í¬ ê°€ì ¸ì˜¤ê¸°
      const allDocuments = await this.firestoreService.getAllDocuments();
      const allChunks: PDFChunk[] = [];
      
      for (const doc of allDocuments) {
        const chunks = await this.firestoreService.getChunksByDocument(doc.id);
        allChunks.push(...chunks);
      }
      
      console.log(`ğŸ“¦ ì´ ${allChunks.length}ê°œ ì²­í¬ ë¡œë“œë¨`);
      
      return allChunks;
      
    } catch (error) {
      console.error('âŒ ëŒ€ëŸ‰ ë°ì´í„° ë¡œë“œ ì‹¤íŒ¨:', error);
      return [];
    }
  }
  
  /**
   * ë‹¤ì¤‘ ì „ëµ ìŠ¤ì½”ì–´ë§ (ì¤‘ë³µ ì—†ìŒ)
   */
  private async scoreChunksByMultipleStrategies(
    chunks: PDFChunk[],
    questionAnalysis: QuestionAnalysis
  ): Promise<Array<{ chunk: Chunk; score: number; breakdown: any }>> {
    // âœ… PDFChunkë¥¼ Chunkë¡œ ë³€í™˜
    const convertedChunks = await this.convertPDFChunksToChunks(chunks);
    
    const results: Array<{ chunk: Chunk; score: number; breakdown: any }> = [];
    
    // ì§ˆë¬¸ ì„ë² ë”© ì‚¬ì „ ê³„ì‚° (ë²¡í„° ê²€ìƒ‰ì—ë§Œ ì‚¬ìš©)
    let questionEmbedding: number[] | null = null;
    try {
      await this.localEmbeddingService.initialize();
      const embedding = await this.localEmbeddingService.embedText(questionAnalysis.context);
      questionEmbedding = embedding;
      console.log(`âœ… ì§ˆë¬¸ ì„ë² ë”© ìƒì„± ì™„ë£Œ: ${embedding.length}ì°¨ì›`);
    } catch (error) {
      console.warn('âš ï¸ ì§ˆë¬¸ ì„ë² ë”© ìƒì„± ì‹¤íŒ¨, ë²¡í„° ìŠ¤ì½”ì–´ë§ ì œì™¸:', error);
    }
    
    console.log('ğŸ“Š ì²­í¬ ìŠ¤ì½”ì–´ë§ ì‹œì‘...');
    
    // ë³‘ë ¬ ì²˜ë¦¬ë¡œ ì„±ëŠ¥ ìµœì í™” (ë°°ì¹˜ ì²˜ë¦¬)
    const BATCH_SIZE = 100;
    for (let i = 0; i < convertedChunks.length; i += BATCH_SIZE) {
      const batch = convertedChunks.slice(i, i + BATCH_SIZE);
      
      const batchPromises = batch.map(async (chunk, index) => {
        const originalChunk = chunks[i + index];
        
        const keywordScore = this.calculateKeywordScore(
          questionAnalysis.keywords,
          originalChunk
        );
        
        const synonymScore = this.calculateSynonymScore(
          questionAnalysis.expandedKeywords || [],
          originalChunk
        );
        
        let semanticScore = 0;
        if (questionEmbedding && originalChunk.embedding) {
          semanticScore = this.calculateSemanticSimilarity(
            questionEmbedding,
            originalChunk.embedding
          );
        }
        
        const totalScore = 
          keywordScore * 0.4 + 
          synonymScore * 0.3 + 
          semanticScore * 0.3;
        
        return {
          chunk,
          score: totalScore,
          breakdown: {
            keyword: keywordScore,
            synonym: synonymScore,
            semantic: semanticScore
          }
        };
      });
      
      const batchResults = await Promise.all(batchPromises);
      results.push(...batchResults);
      
      if (i % 500 === 0) {
        console.log(`  ì§„í–‰ë¥ : ${Math.min(i + BATCH_SIZE, convertedChunks.length)}/${convertedChunks.length}`);
      }
    }
    
    return results;
  }
  
  /**
   * í‚¤ì›Œë“œ ì ìˆ˜ ê³„ì‚° (0~1)
   */
  private calculateKeywordScore(keywords: string[], chunk: PDFChunk): number {
    let score = 0;
    let matches = 0;
    
    keywords.forEach(keyword => {
      const keywordLower = keyword.toLowerCase();
      const contentLower = (chunk.content || '').toLowerCase();
      const keywordsLower = (chunk.keywords || []).map(k => k.toLowerCase());
      
      // keywords ë°°ì—´ì—ì„œ ì •í™•íˆ ë§¤ì¹­
      if (keywordsLower.includes(keywordLower)) {
        score += 10;
        matches++;
      }
      // contentì—ì„œ í¬í•¨ ì—¬ë¶€
      else if (contentLower.includes(keywordLower)) {
        const count = (contentLower.match(new RegExp(keywordLower, 'g')) || []).length;
        score += Math.min(count * 2, 10);
        matches++;
      }
    });
    
    if (matches === 0) return 0;
    
    return Math.min(score / (keywords.length * 10), 1.0);
  }
  
  /**
   * ë™ì˜ì–´ ì ìˆ˜ ê³„ì‚° (0~1)
   */
  private calculateSynonymScore(expandedKeywords: string[], chunk: PDFChunk): number {
    if (expandedKeywords.length === 0) return 0;
    
    let score = 0;
    const contentLower = (chunk.content || '').toLowerCase();
    
    expandedKeywords.forEach(synonym => {
      const synonymLower = synonym.toLowerCase();
      
      if (contentLower.includes(synonymLower)) {
        const count = (contentLower.match(new RegExp(synonymLower, 'g')) || []).length;
        score += Math.min(count, 5);
      }
    });
    
    return Math.min(score / (expandedKeywords.length * 5), 1.0);
  }
  
  /**
   * ì˜ë¯¸ì  ìœ ì‚¬ë„ ê³„ì‚° (ì½”ì‚¬ì¸ ìœ ì‚¬ë„)
   */
  private calculateSemanticSimilarity(vector1: number[], vector2: number[]): number {
    try {
      // ë²¡í„° ê¸¸ì´ ë§ì¶”ê¸°
      const maxLength = Math.max(vector1.length, vector2.length);
      const v1 = this.padVector(vector1, maxLength);
      const v2 = this.padVector(vector2, maxLength);
      
      // ë‚´ì  ê³„ì‚°
      let dotProduct = 0;
      let magnitude1 = 0;
      let magnitude2 = 0;
      
      for (let i = 0; i < maxLength; i++) {
        dotProduct += v1[i] * v2[i];
        magnitude1 += v1[i] * v1[i];
        magnitude2 += v2[i] * v2[i];
      }
      
      magnitude1 = Math.sqrt(magnitude1);
      magnitude2 = Math.sqrt(magnitude2);
      
      if (magnitude1 === 0 || magnitude2 === 0) return 0;
      
      return dotProduct / (magnitude1 * magnitude2);
    } catch (error) {
      console.warn('âš ï¸ ì˜ë¯¸ì  ìœ ì‚¬ë„ ê³„ì‚° ì‹¤íŒ¨:', error);
      return 0;
    }
  }
  
  /**
   * ë²¡í„° ê¸¸ì´ ë§ì¶”ê¸°
   */
  private padVector(vector: number[], targetLength: number): number[] {
    if (vector.length >= targetLength) {
      return vector.slice(0, targetLength);
    }
    
    const padded = [...vector];
    while (padded.length < targetLength) {
      padded.push(0);
    }
    return padded;
  }
  
  /**
   * PDFChunkë¥¼ Chunkë¡œ ë³€í™˜
   */
  private async convertPDFChunksToChunks(pdfChunks: PDFChunk[]): Promise<Chunk[]> {
    // documentIdë³„ë¡œ ê·¸ë£¹í™”í•˜ì—¬ ì¤‘ë³µ ì¡°íšŒ ë°©ì§€
    const documentIds = [...new Set(pdfChunks.map(p => p.documentId))];
    
    // ëª¨ë“  ë¬¸ì„œ ì •ë³´ ì¡°íšŒ
    const documents = await Promise.all(
      documentIds.map(id => this.firestoreService.getDocumentById(id))
    );
    
    // documentId -> PDFDocument ë§µ ìƒì„±
    const docMap = new Map(documents.filter(d => d !== null).map(d => [d.id, d]));
    
    return pdfChunks.map(pdfChunk => {
      const doc = docMap.get(pdfChunk.documentId);
      
      return {
        id: pdfChunk.id || '',
        content: pdfChunk.content,
        metadata: {
          source: pdfChunk.metadata.source || doc?.filename || 'Firestore',
          title: pdfChunk.metadata.title || doc?.title || 'Unknown',
          page: pdfChunk.metadata.page || 0,
          section: pdfChunk.metadata.section || 'general',
          position: pdfChunk.metadata.position || 0,
          startPosition: pdfChunk.metadata.startPos || 0,
          endPosition: pdfChunk.metadata.endPos || 0,
          originalSize: pdfChunk.metadata.originalSize || 0,
          documentType: pdfChunk.metadata.documentType
        },
        keywords: pdfChunk.keywords || [],
        location: {
          document: pdfChunk.location?.document || doc?.title || pdfChunk.documentId || 'Unknown',
          section: pdfChunk.location?.section || pdfChunk.metadata.section || 'general',
          page: pdfChunk.location?.page || pdfChunk.metadata.page || 0
        }
      };
    });
  }
  
  /**
   * ì¤‘ë³µ ì œê±° ë° ë­í‚¹
   */
  private removeDuplicatesAndRank(
    scoredChunks: Array<{ chunk: Chunk; score: number; breakdown: any }>,
    maxChunks: number
  ): Array<{ chunk: Chunk; score: number; breakdown: any }> {
    // ì¤‘ë³µ ì œê±° (ë™ì¼í•œ ID)
    const uniqueMap = new Map<string, { chunk: Chunk; score: number; breakdown: any }>();
    
    scoredChunks.forEach(scored => {
      const existing = uniqueMap.get(scored.chunk.id || '');
      
      if (!existing || existing.score < scored.score) {
        uniqueMap.set(scored.chunk.id || '', scored);
      }
    });
    
    // ì ìˆ˜ ìˆœìœ¼ë¡œ ì •ë ¬
    const uniqueChunks = Array.from(uniqueMap.values());
    uniqueChunks.sort((a, b) => b.score - a.score);
    
    // ìµœëŒ€ ê°œìˆ˜ ì œí•œ
    return uniqueChunks.slice(0, maxChunks);
  }
  
  /**
   * í‰ê·  ê´€ë ¨ì„± ê³„ì‚°
   */
  private calculateAverageRelevance(chunks: EnhancedChunk[]): number {
    if (chunks.length === 0) return 0;
    
    const sum = chunks.reduce((acc, chunk) => acc + (chunk.relevanceScore || 0), 0);
    return sum / chunks.length;
  }
  
  /**
   * ì ìˆ˜ ë¶„í¬ ê³„ì‚°
   */
  private calculateScoreBreakdown(scoredChunks: ScoredChunk[]): {
    keyword: number;
    synonym: number;
    semantic: number;
  } {
    if (scoredChunks.length === 0) {
      return { keyword: 0, synonym: 0, semantic: 0 };
    }
    
    const sums = scoredChunks.reduce(
      (acc, scored) => ({
        keyword: acc.keyword + scored.breakdown.keyword,
        synonym: acc.synonym + scored.breakdown.synonym,
        semantic: acc.semantic + scored.breakdown.semantic
      }),
      { keyword: 0, synonym: 0, semantic: 0 }
    );
    
    return {
      keyword: sums.keyword / scoredChunks.length,
      synonym: sums.synonym / scoredChunks.length,
      semantic: sums.semantic / scoredChunks.length
    };
  }
}
